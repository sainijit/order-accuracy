# **Order Accuracy**

This project processes a video or RTSP stream, extracts **valid order-ID frames**, uploads them to **MinIO**, selects the **top frames per order**, and runs **VLM inference** to extract ordered items.

## ğŸ”§ **VLM Backend Support**

The system supports **two VLM backends**:

1. **Embedded VLM** (Default) - OpenVINO GenAI running directly in application container
   - Model: Qwen2.5-VL-7B-Instruct (int8, ~7GB)
   - Device: GPU (Intel Arc iGPU)
   - Best for: Single deployment, lower latency

2. **OVMS Backend** - External OpenVINO Model Server
   - Model: Qwen2-VL-2B-Instruct (int4, ~2GB)
   - Device: GPU via OVMS service
   - Best for: Multiple applications, resource efficiency, scalability

**Quick Backend Switch**: See [QUICK_START_BACKEND_SWITCH.md](QUICK_START_BACKEND_SWITCH.md)

## ğŸ§  **Semantic Comparison Service**

Integrated AI-powered semantic matching microservice for intelligent item comparison:

- **Multiple Matching Strategies**: Exact â†’ Semantic â†’ Hybrid
- **VLM-Powered**: Uses OVMS for semantic reasoning
- **Automatic Fallback**: Falls back to local matching if service unavailable
- **Caching**: Memory/Redis cache for performance
- **Metrics**: Prometheus metrics at port 9090

**Example:** Matches "green apple" â†” "apple" using semantic reasoning

See [SEMANTIC_SERVICE_INTEGRATION.md](SEMANTIC_SERVICE_INTEGRATION.md) for details.

---

## ğŸ“¦ **What the system does**

* Accepts **video file uploads** or **RTSP streams**
* Extracts frames using **GStreamer + gvapython**
* Detects **order ID using OCR**
* Stores frames in **MinIO**
* Selects **Top-K frames** per order using **YOLO**
* Runs **VLM (OpenVINO GenAI)** for item & quantity extraction
* Provides a **Gradio UI** for interaction

---

## ğŸ“ **Project Structure**

```
order-accuracy/
â”‚
â”œâ”€â”€ docker-compose.yaml           # Multi-service orchestration
â”œâ”€â”€ config/
â”‚   â””â”€â”€ application.yaml          # Backend configuration
â”‚
â”œâ”€â”€ ovms-service/                 # OVMS model server (optional)
â”‚   â”œâ”€â”€ setup_models.sh           # Model setup script
â”‚   â”œâ”€â”€ export_model.py           # Export HF models to OpenVINO
â”‚   â”œâ”€â”€ export_requirements.txt   # Model export dependencies
â”‚   â”œâ”€â”€ models_vlm/               # OVMS model repository
â”‚   â”‚   â”œâ”€â”€ config.json           # OVMS configuration
â”‚   â”‚   â””â”€â”€ Qwen/                 # Model files (after setup)
â”‚   â””â”€â”€ README.md                 # OVMS setup documentation
â”‚
â”œâ”€â”€ application-service/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ main.py               # API + pipeline trigger
â”‚       â”œâ”€â”€ vlm_service.py        # VLM inference service
â”‚       â”œâ”€â”€ vlm_backend_factory.py # Backend factory pattern
â”‚       â”œâ”€â”€ ovms_client.py        # OVMS HTTP client
â”‚       â”œâ”€â”€ pipeline_runner.py    # GStreamer launcher
â”‚       â”œâ”€â”€ frame_pipeline.py     # OCR + frame upload
â”‚       â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frame-selector-service/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ frame_selector.py     # Selects top frames
â”‚       â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ gradio-ui/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ gradio_app.py             # Web UI
â”‚
â”œâ”€â”€ model/                        # Embedded VLM model (optional)
â”‚   â””â”€â”€ Qwen2.5-VL-7B-Instruct-ov-int8/
â”‚
â””â”€â”€ storage/
    â”œâ”€â”€ videos/
    â””â”€â”€ uploads/
```

---

## â–¶ï¸ **How to Run**

### **Option 1: Embedded VLM (Default)**

```bash
# Start all services
docker-compose up --build -d
```

### **Option 2: OVMS Backend**

```bash
# 1. Set up OVMS models (first time only)
cd ovms-service
./setup_models.sh
cd ..

# 2. Change backend in config/application.yaml:
#    vlm:
#      backend: ovms

# 3. Change environment in docker-compose.yaml:
#    VLM_BACKEND: ovms

# 4. Start services with OVMS
docker-compose --profile ovms up --build -d
```

**Verify OVMS is running:**
```bash
curl http://localhost:8001/v1/config
curl http://localhost:8001/v1/models
```

This launches:

* **MinIO** (frame storage)
* **Application Service** (GStreamer + OCR + VLM API)
* **Frame Selector Service** (YOLO ranking)
* **Gradio UI**
* **OVMS VLM Service** (when using OVMS backend)

---

Login for MinIO:

```
minioadmin / minioadmin
```

---

## ğŸ¥ **How to Use**

### **Upload a Video (UI)**

1. Open Gradio UI
2. Upload `.mp4 / .avi / .mkv`
3. Click **Upload & Start**

The pipeline starts automatically.

---

### **RTSP Stream**

RTSP example:

```
rtsp://192.168.1.5:8554/test
```

API call:

```bash
curl -X POST http://localhost:8000/run-video \
  -H "Content-Type: application/json" \
  -d '{"source_type":"rtsp","source":"rtsp://192.168.1.5:8554/test"}'
```

> If `localhost` is provided in RTSP, the backend safely normalizes it for Docker.

---

## ğŸ–¼ **View Frames in MinIO**

### Extracted Frames

```
frames/
 â””â”€â”€ <order_id>/
      â”œâ”€â”€ 11.jpg
      â”œâ”€â”€ 42.jpg
      â””â”€â”€ 76.jpg
```

### Selected Frames

```
selected/
 â””â”€â”€ <order_id>/
      â”œâ”€â”€ rank_1.jpg
      â”œâ”€â”€ rank_2.jpg
      â””â”€â”€ rank_3.jpg
```

---

## ğŸ”„ **Clean Restart (Recommended)**

```bash
docker compose down --remove-orphans
docker volume rm order-accuracy_minio_data
docker compose up --build
```

âš ï¸ This deletes all stored frames.

---

## âœ… **TL;DR**

```bash
docker compose up --build
open http://localhost:7860
```

Upload video or RTSP â†’ frames extracted â†’ top frames selected â†’ VLM results available.
